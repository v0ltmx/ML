{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from imblearn.under_sampling import NearMiss \r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import cross_validate\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Dataset\r\n",
    "df = pd.read_csv('./bases/water_mod.csv', decimal=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removendo colunas irrelevantes\r\n",
    "dfdrop = df.drop(columns=['Solids', 'Conductivity'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Verificando se existem valores zerados\r\n",
    "df.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Removendo os valores zerados\r\n",
    "df.dropna(inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Reduzindo casas decimais\r\n",
    "df = df.apply(pd.to_numeric)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Visualizando outliers\r\n",
    "df['ph'].plot(kind = 'box')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Tratando os outliers (foram tratados um por vez)\r\n",
    "\r\n",
    "\r\n",
    "#dfTeste = df.copy()\r\n",
    "\r\n",
    "q1 = dfTeste['Turbidity'].quantile(0.25)\r\n",
    "q3 = dfTeste['Turbidity'].quantile(0.75)\r\n",
    "iqr = q3 - q1\r\n",
    "lLim = q1 - 1.5 * iqr \r\n",
    "hLim = q3 + 1.5 * iqr\r\n",
    "dfTeste.loc[dfTeste['Turbidity'] < lLim, 'Turbidity'] = lLim #substitui os valores abaixo do limite inferior pelo limite inferior\r\n",
    "dfTeste.loc[dfTeste['Turbidity'] > hLim, 'Turbidity'] = hLim #substitui os valores acima do limite superior pelo limite superior\r\n",
    "\r\n",
    "print(dfTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfTeste['ph'].plot(kind = 'box')\r\n",
    "df = dfTeste"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Verificando o balanceamento\r\n",
    "df.Potability.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Tratando os outliers (foram tratados um por vez)\r\n",
    "\r\n",
    "\r\n",
    "#dfTeste = df.copy()\r\n",
    "\r\n",
    "q1 = dfTeste['Turbidity'].quantile(0.25)\r\n",
    "q3 = dfTeste['Turbidity'].quantile(0.75)\r\n",
    "iqr = q3 - q1\r\n",
    "lLim = q1 - 1.5 * iqr \r\n",
    "hLim = q3 + 1.5 * iqr\r\n",
    "dfTeste.loc[dfTeste['Turbidity'] < lLim, 'Turbidity'] = lLim #substitui os valores abaixo do limite inferior pelo limite inferior\r\n",
    "dfTeste.loc[dfTeste['Turbidity'] > hLim, 'Turbidity'] = hLim #substitui os valores acima do limite superior pelo limite superior\r\n",
    "\r\n",
    "print(dfTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Verificando outliers pós tratamento\r\n",
    "dfTeste['Turbidity'].plot(kind = 'box')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Balanceando linhas de acordo com coluna alvo\r\n",
    "from imblearn.under_sampling import NearMiss \r\n",
    "\r\n",
    "X, y = NearMiss().fit_resample(df.drop(columns=['Potability']), df['Potability'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfTeste = pd.DataFrame(X, columns=df.columns.drop('Potability'))\r\n",
    "dfTeste['Potability'] = y\r\n",
    "print(dfTeste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfTeste['Potability'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "class runmodel:\r\n",
    "  '''\r\n",
    "    Parâmetros de entrada:\r\n",
    "\r\n",
    "    X: atributos de entradas\r\n",
    "    y: atributo alvo\r\n",
    "    model: algoritmo para construção do estimador\r\n",
    "    cv: se None faz N holdouts, se int faz validação cruzada (ambos com estratificação por classe)\r\n",
    "    n = quantidade de repetições da amostragem\r\n",
    "\r\n",
    "    Guardar as métricas de cada execução (armazenametricas) e \r\n",
    "    Mostrar os valores médios com desvio padrão para as métricas (mostraresultadomedio) \r\n",
    "\r\n",
    "    Se dataset tiver mais de 2 classes, adaptar resultados    \r\n",
    "  '''\r\n",
    "\r\n",
    "  def __init__(self, X, y, model, cv = None, n = 1):\r\n",
    "    \r\n",
    "    self.__resultados = {\r\n",
    "      'precision_0': [],\r\n",
    "      'recall_0': [],\r\n",
    "      'f1_0': [],\r\n",
    "      'support_0': [],\r\n",
    "      'precision_1': [],\r\n",
    "      'recall_1': [],\r\n",
    "      'f1_1': [],\r\n",
    "      'support_1' : [],\r\n",
    "      'accuracy' : [],\r\n",
    "      'precision_wavg' : [],\r\n",
    "      'recall_wavg' : [],\r\n",
    "      'f1_wavg' : [],\r\n",
    "      'support_wavg' : []\r\n",
    "    }\r\n",
    "\r\n",
    "    if cv is None:\r\n",
    "      print(f'{n} holdouts')\r\n",
    "      for i in range(n):\r\n",
    "        self.__avaliamodelo(X, y, model)\r\n",
    "    \r\n",
    "    else:\r\n",
    "      print(f'{n} validação cruzada com {cv} folds')\r\n",
    "      for i in range(n):\r\n",
    "        self.__avaliamodelo_cv(X, y, model, cv)\r\n",
    "\r\n",
    "  @property\r\n",
    "  def resultados(self):\r\n",
    "    return self.__resultados\r\n",
    "\r\n",
    "  def __avaliamodelo(self, X, y, model):\r\n",
    "    #gera as amostras de treino (2/3) e teste (1/3) com estratificação por classe\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify = y)\r\n",
    "    # Treina o modelo usando os dados de treino\r\n",
    "    model.fit(X_train,y_train)\r\n",
    "    # Testa modelo usando os dados de teste\r\n",
    "    pred = model.predict(X_test)\r\n",
    "    #armazena resultado\r\n",
    "    self.__armazenametricas(metrics.classification_report(y_test,pred, output_dict= True))\r\n",
    "\r\n",
    "  def __avaliamodelo_cv(self, X, y, model, cv):\r\n",
    "    #gera as amostras para cv folds com embaralhamento (permite fazer várias validações cruzadas)\r\n",
    "    skf = StratifiedKFold(shuffle=True, n_splits=cv)\r\n",
    "    #para cada fold: treina, testa e armazena os resultados\r\n",
    "    for train_index, test_index in skf.split(X, y):\r\n",
    "      model.fit(X.iloc[train_index], y.iloc[train_index])\r\n",
    "      pred = model.predict(X.iloc[test_index])\r\n",
    "      self.__armazenametricas(metrics.classification_report(y.iloc[test_index], pred, output_dict= True))\r\n",
    "\r\n",
    "  def __armazenametricas(self, d):\r\n",
    "    self.__resultados['precision_0'].append(d['0']['precision'])\r\n",
    "    self.__resultados['recall_0'].append(d['0']['recall'])\r\n",
    "    self.__resultados['f1_0'].append(d['0']['f1-score'])\r\n",
    "    self.__resultados['support_0'].append(d['0']['support'])\r\n",
    "\r\n",
    "    self.__resultados['precision_1'].append(d['1']['precision'])\r\n",
    "    self.__resultados['recall_1'].append(d['1']['recall'])\r\n",
    "    self.__resultados['f1_1'].append(d['1']['f1-score'])\r\n",
    "    self.__resultados['support_1'].append(d['1']['support'])\r\n",
    "\r\n",
    "    self.__resultados['accuracy'].append(d['accuracy'])\r\n",
    "    \r\n",
    "    self.__resultados['precision_wavg'].append(d['weighted avg']['precision'])\r\n",
    "    self.__resultados['recall_wavg'].append(d['weighted avg']['recall'])\r\n",
    "    self.__resultados['f1_wavg'].append(d['weighted avg']['f1-score'])\r\n",
    "    self.__resultados['support_wavg'].append(d['weighted avg']['support'])\r\n",
    "\r\n",
    "  def mostraresultadomedio(self):\r\n",
    "    print(f\"\\t\\t precision \\t recall \\t f1-score \\t support\\n\")\r\n",
    "    print(f\"0 \\t\\t {round(np.mean(self.__resultados['precision_0']), 2)}({round(np.std(self.__resultados['precision_0']),2)}) \\t {round(np.mean(self.__resultados['recall_0']),2)}({round(np.std(self.__resultados['recall_0']),2)}) \\t {round(np.mean(self.__resultados['f1_0']),2)}({round(np.std(self.__resultados['f1_0']),2)}) \\t {round(np.mean(self.__resultados['support_0']),2)}({round(np.std(self.__resultados['support_0']),2)})\\n\")\r\n",
    "    print(f\"1 \\t\\t {round(np.mean(self.__resultados['precision_1']), 2)}({round(np.std(self.__resultados['precision_1']),2)}) \\t {round(np.mean(self.__resultados['recall_1']),2)}({round(np.std(self.__resultados['recall_1']),2)}) \\t {round(np.mean(self.__resultados['f1_1']),2)}({round(np.std(self.__resultados['f1_1']),2)}) \\t {round(np.mean(self.__resultados['support_1']),2)}({round(np.std(self.__resultados['support_1']),2)})\\n\")\r\n",
    "    print(f\"accuracy \\t\\t  \\t\\t  \\t {round(np.mean(self.__resultados['accuracy']), 2)}({round(np.std(self.__resultados['accuracy']),2)}) \\t\\t \\n\")\r\n",
    "    print(f\"weighted avg \\t {round(np.mean(self.__resultados['precision_wavg']), 2)}({round(np.std(self.__resultados['precision_wavg']),2)}) \\t {round(np.mean(self.__resultados['recall_wavg']),2)}({round(np.std(self.__resultados['recall_wavg']),2)}) \\t {round(np.mean(self.__resultados['f1_wavg']),2)}({round(np.std(self.__resultados['f1_wavg']),2)}) \\t {round(np.mean(self.__resultados['support_wavg']),2)}({round(np.std(self.__resultados['support_wavg']),2)})\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicando KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfTeste.drop(columns=['Potability']), dfTeste['Potability'],test_size=0.33, stratify=dfTeste['Potability'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#define os parâmetros a serem testados com o KNN\r\n",
    "param_grid_knn = {'n_neighbors': range(1,40,2), 'weights': ['uniform', 'distance'], 'p': [1, 2, 3]} \r\n",
    "#cria o objeto do gridsearchcv\r\n",
    "gridknn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, scoring = 'f1_weighted', cv = 10, verbose = 1)\r\n",
    "#executa o gridsearchcv para a base separando X e y\r\n",
    "gridknn.fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridknn.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridknn.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_predictions = gridknn.predict(X_test)\r\n",
    "print(metrics.classification_report(y_test, grid_predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn = gridknn.best_estimator_\r\n",
    "cross_validation_knn = runmodel(dfTeste.drop(columns=['Potability']), dfTeste['Potability'], knn, cv = 10, n = 1 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('\\tMédia e desvio padrão do KNN ~ 10 fold cross validation\\n')\r\n",
    "cross_validation_knn.mostraresultadomedio()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Observando a Classe\r\n",
    "sns.pairplot(data=dfTeste, hue='Potability')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicando Naive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfTeste.drop(columns=['Potability']), dfTeste['Potability'],test_size=0.33, stratify=dfTeste['Potability'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = GaussianNB()\r\n",
    "model.fit(X_train,y_train)\r\n",
    "pred = model.predict(X_test)\r\n",
    "\r\n",
    "print(metrics.classification_report(y_test, pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Teste com validação cruzada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cross_validation_naive = runmodel(dfTeste.drop(columns=['Potability']), dfTeste['Potability'], GaussianNB(), cv = 10, n = 1 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cross_validation_naive.mostraresultadomedio()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicando SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#'kernel': ['rbf', 'poly', 'sigmoid', 'linear']\r\n",
    "param_grid = {\r\n",
    "    'C': [0.1, 1, 10, 100], \r\n",
    "    'gamma': [0.1, 0.01, 0.001, 'auto', 'scale'], \r\n",
    "    'kernel': ['sigmoid']\r\n",
    "} \r\n",
    "gridsvm = GridSearchCV(SVC(),param_grid, verbose = 3)\r\n",
    "gridsvm.fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridsvm.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Teste de validação cruzada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svm = gridsvm.best_estimator_\r\n",
    "cross_validation_svm = runmodel(dfTeste.drop(columns=['Potability']), dfTeste['Potability'], svm, cv = 10, n = 1 )\r\n",
    "print(metrics.classification_report(y_test, grid_predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_predictions = gridsvm.predict(X_test)\r\n",
    "cross_validation_svm.mostraresultadomedio()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rede neural - MLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfTeste.drop(columns=['Potability']), dfTeste['Potability'],test_size=0.33, stratify=dfTeste['Potability'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#configuração default\r\n",
    "mlp = MLPClassifier()\r\n",
    "mlp.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import metrics\r\n",
    "pred = mlp.predict(X_test)\r\n",
    "print(metrics.classification_report(y_test, pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid_mlp = {\r\n",
    "    'hidden_layer_sizes': [(100, ), (7,)], #default e heurístico\r\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\r\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\r\n",
    "    'max_iter': [200, 1000, 5000, 10000]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "\r\n",
    "gridmlp = GridSearchCV(MLPClassifier(),param_grid_mlp, verbose = 1)\r\n",
    "\r\n",
    "gridmlp.fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridmlp.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridmlp.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridmlp.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Teste de validação cruzada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlp = gridmlp.best_estimator_\r\n",
    "cross_validation_mlp = runmodel(dfTeste.drop(columns=['Potability']), dfTeste['Potability'], mlp, cv = 10, n = 1 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('\\tMédia e desvio padrão do MLP com 10 fold cross validation\\n')\r\n",
    "cross_validation_mlp.mostraresultadomedio()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}